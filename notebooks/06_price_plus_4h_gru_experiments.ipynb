{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c33063",
   "metadata": {},
   "source": [
    "# Notebook 06 – GRU on Daily + 4h Intraday Features (SPY)\n",
    "\n",
    "Goal: Train a GRU sequence model on daily SPY data augmented with 4-hour intraday\n",
    "summary features, and compare performance to the price-only GRU and MLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092e9c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP only\\Documents\\ANN_Final_Project\\spy-ann C:\\Users\\KDP only\\Documents\\ANN_Final_Project\\spy-ann\\data\\processed\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "DATA_PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(ROOT, DATA_PROC)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f88cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>ma_close_5</th>\n",
       "      <th>ma_close_20</th>\n",
       "      <th>...</th>\n",
       "      <th>label_up</th>\n",
       "      <th>intraday_mean_ret_4h</th>\n",
       "      <th>intraday_std_ret_4h</th>\n",
       "      <th>intraday_n_up_4h</th>\n",
       "      <th>intraday_n_candles_4h</th>\n",
       "      <th>intraday_high_max</th>\n",
       "      <th>intraday_low_min</th>\n",
       "      <th>intraday_frac_up_4h</th>\n",
       "      <th>intraday_range_4h</th>\n",
       "      <th>intraday_last_ret_4h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>461.944824</td>\n",
       "      <td>462.933380</td>\n",
       "      <td>459.909019</td>\n",
       "      <td>460.975862</td>\n",
       "      <td>70375300</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>458.495721</td>\n",
       "      <td>448.292444</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>472.980011</td>\n",
       "      <td>470.799988</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.180023</td>\n",
       "      <td>-0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>464.753906</td>\n",
       "      <td>464.832224</td>\n",
       "      <td>462.414688</td>\n",
       "      <td>462.492975</td>\n",
       "      <td>55761800</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>460.964941</td>\n",
       "      <td>449.389354</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>474.920013</td>\n",
       "      <td>472.450012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.470001</td>\n",
       "      <td>0.001793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>458.313660</td>\n",
       "      <td>465.791362</td>\n",
       "      <td>457.883003</td>\n",
       "      <td>463.892568</td>\n",
       "      <td>102921000</td>\n",
       "      <td>-0.013857</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>460.898364</td>\n",
       "      <td>450.212508</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.894989</td>\n",
       "      <td>467.820007</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.074982</td>\n",
       "      <td>-0.015960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>462.659332</td>\n",
       "      <td>462.933384</td>\n",
       "      <td>458.881307</td>\n",
       "      <td>461.318408</td>\n",
       "      <td>86667500</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>461.406531</td>\n",
       "      <td>451.167650</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>472.975006</td>\n",
       "      <td>468.839996</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.135010</td>\n",
       "      <td>0.005520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>463.589111</td>\n",
       "      <td>465.282375</td>\n",
       "      <td>461.680550</td>\n",
       "      <td>463.794642</td>\n",
       "      <td>67160400</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>462.252167</td>\n",
       "      <td>452.155632</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.380005</td>\n",
       "      <td>471.700012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.679993</td>\n",
       "      <td>-0.002065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       Close        High         Low        Open     Volume  \\\n",
       "0 2023-12-18  461.944824  462.933380  459.909019  460.975862   70375300   \n",
       "1 2023-12-19  464.753906  464.832224  462.414688  462.492975   55761800   \n",
       "2 2023-12-20  458.313660  465.791362  457.883003  463.892568  102921000   \n",
       "3 2023-12-21  462.659332  462.933384  458.881307  461.318408   86667500   \n",
       "4 2023-12-22  463.589111  465.282375  461.680550  463.794642   67160400   \n",
       "\n",
       "     ret_1d  log_ret_1d  ma_close_5  ma_close_20  ...  label_up  \\\n",
       "0  0.005625    0.005609  458.495721   448.292444  ...         1   \n",
       "1  0.006081    0.006063  460.964941   449.389354  ...         0   \n",
       "2 -0.013857   -0.013954  460.898364   450.212508  ...         1   \n",
       "3  0.009482    0.009437  461.406531   451.167650  ...         1   \n",
       "4  0.002010    0.002008  462.252167   452.155632  ...         1   \n",
       "\n",
       "   intraday_mean_ret_4h  intraday_std_ret_4h  intraday_n_up_4h  \\\n",
       "0             -0.001090                  NaN               1.0   \n",
       "1              0.002973             0.001668               2.0   \n",
       "2             -0.007190             0.012402               1.0   \n",
       "3              0.005020             0.000708               1.0   \n",
       "4              0.000988             0.004317               1.0   \n",
       "\n",
       "   intraday_n_candles_4h  intraday_high_max  intraday_low_min  \\\n",
       "0                    2.0         472.980011        470.799988   \n",
       "1                    2.0         474.920013        472.450012   \n",
       "2                    2.0         475.894989        467.820007   \n",
       "3                    2.0         472.975006        468.839996   \n",
       "4                    2.0         475.380005        471.700012   \n",
       "\n",
       "   intraday_frac_up_4h  intraday_range_4h  intraday_last_ret_4h  \n",
       "0                  0.5           2.180023             -0.001090  \n",
       "1                  1.0           2.470001              0.001793  \n",
       "2                  0.5           8.074982             -0.015960  \n",
       "3                  0.5           4.135010              0.005520  \n",
       "4                  0.5           3.679993             -0.002065  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (260, 24)\n",
      "Date range: 2023-12-18 00:00:00 → 2024-12-30 00:00:00\n",
      "\n",
      "Label distribution (proportion):\n",
      "label_up\n",
      "1    0.592308\n",
      "0    0.407692\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = DATA_PROC / \"daily_with_4h.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "print(\"=== DATA PREVIEW ===\")\n",
    "display(df.head())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"Date range:\", df[\"date\"].min(), \"→\", df[\"date\"].max())\n",
    "print(\"\\nLabel distribution (proportion):\")\n",
    "print(df[\"label_up\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1523b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature columns:\n",
      "['Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20', 'intraday_mean_ret_4h', 'intraday_std_ret_4h', 'intraday_n_up_4h', 'intraday_n_candles_4h', 'intraday_high_max', 'intraday_low_min', 'intraday_frac_up_4h', 'intraday_range_4h', 'intraday_last_ret_4h']\n",
      "Number of features: 20\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\"date\", \"future_price\", \"future_ret_1d\", \"label_up\"]\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "print(\"\\nFeature columns:\")\n",
    "print(feature_cols)\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "\n",
    "X_all = df[feature_cols].values.astype(\"float32\")\n",
    "y_all = df[\"label_up\"].values.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768b32a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices:\n",
      "Train: 0 → 181 | count: 182\n",
      "Val  : 182 → 220 | count: 39\n",
      "Test : 221 → 259 | count: 39\n",
      "\n",
      "Raw split sizes:\n",
      "Train: 182\n",
      "Val  : 39\n",
      "Test : 39\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "train_end = int(n * 0.7)\n",
    "val_end   = int(n * 0.85)\n",
    "\n",
    "train_idx = np.arange(0, train_end)\n",
    "val_idx   = np.arange(train_end, val_end)\n",
    "test_idx  = np.arange(val_end, n)\n",
    "\n",
    "print(\"Indices:\")\n",
    "print(\"Train:\", train_idx[0], \"→\", train_idx[-1], \"| count:\", len(train_idx))\n",
    "print(\"Val  :\", val_idx[0],   \"→\", val_idx[-1],   \"| count:\", len(val_idx))\n",
    "print(\"Test :\", test_idx[0],  \"→\", test_idx[-1],  \"| count:\", len(test_idx))\n",
    "\n",
    "X_train = X_all[train_idx]\n",
    "y_train = y_all[train_idx]\n",
    "\n",
    "X_val = X_all[val_idx]\n",
    "y_val = y_all[val_idx]\n",
    "\n",
    "X_test = X_all[test_idx]\n",
    "y_test = y_all[test_idx]\n",
    "\n",
    "print(\"\\nRaw split sizes:\")\n",
    "print(\"Train:\", X_train.shape[0])\n",
    "print(\"Val  :\", X_val.shape[0])\n",
    "print(\"Test :\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af78cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f586683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_windows(X, y, window_size: int):\n",
    "    \"\"\"\n",
    "    X: (N, F), y: (N,)\n",
    "    Returns:\n",
    "        X_seq: (N_windows, W, F)\n",
    "        y_seq: (N_windows,)\n",
    "    Each window uses rows [i, ..., i+W-1], target is y[i+W]\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    n = len(X)\n",
    "    max_start = n - window_size - 1  # need i+W to exist\n",
    "\n",
    "    if max_start < 0:\n",
    "        return np.empty((0, window_size, X.shape[1]), dtype=X.dtype), np.empty((0,), dtype=y.dtype)\n",
    "\n",
    "    seqs = []\n",
    "    targets = []\n",
    "    for i in range(max_start + 1):\n",
    "        seq = X[i : i + window_size]     # (W, F)\n",
    "        target = y[i + window_size]      # scalar\n",
    "        seqs.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "    X_seq = np.stack(seqs, axis=0)\n",
    "    y_seq = np.array(targets, dtype=y.dtype)\n",
    "    return X_seq, y_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2172a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_seq: np.ndarray, y_seq: np.ndarray):\n",
    "        self.X = X_seq\n",
    "        self.y = y_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)  # (W, F)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)  # scalar 0/1\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36867f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 32, num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        \"\"\"\n",
    "        out, h_n = self.gru(x)       # h_n: (num_layers, batch, hidden_dim)\n",
    "        last_hidden = h_n[-1]        # (batch, hidden_dim)\n",
    "        logits = self.fc(last_hidden).squeeze(-1)  # (batch,)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240863a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru_price_plus_4h(\n",
    "    window_size: int,\n",
    "    hidden_dim: int,\n",
    "    num_layers: int = 1,\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 25,\n",
    "    lr: float = 1e-3,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    # Build windowed datasets\n",
    "    Xtr_seq, ytr_seq = build_windows(X_train_scaled, y_train, window_size)\n",
    "    Xval_seq, yval_seq = build_windows(X_val_scaled, y_val, window_size)\n",
    "    Xte_seq, yte_seq = build_windows(X_test_scaled, y_test, window_size)\n",
    "\n",
    "    print(f\"\\n=== GRU price+4h: W={window_size}, hidden={hidden_dim}, layers={num_layers} ===\")\n",
    "    print(\"Train windows:\", Xtr_seq.shape[0], \"Val windows:\", Xval_seq.shape[0], \"Test windows:\", Xte_seq.shape[0])\n",
    "\n",
    "    if Xtr_seq.shape[0] == 0 or Xval_seq.shape[0] == 0 or Xte_seq.shape[0] == 0:\n",
    "        print(\"Not enough data for this window size; skipping.\")\n",
    "        return {\n",
    "            \"window_size\": window_size,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"best_val_acc\": float(\"nan\"),\n",
    "            \"test_acc\": float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    train_ds = SeqDataset(Xtr_seq, ytr_seq)\n",
    "    val_ds   = SeqDataset(Xval_seq, yval_seq)\n",
    "    test_ds  = SeqDataset(Xte_seq, yte_seq)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_dim = Xtr_seq.shape[2]\n",
    "    model = GRUNet(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            total_correct += (preds == yb).float().sum().item()\n",
    "            total_examples += yb.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        train_acc  = total_correct / total_examples\n",
    "\n",
    "        # ---- Val ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "                val_loss += loss.item() * yb.size(0)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                preds = (probs >= 0.5).float()\n",
    "                val_correct += (preds == yb).float().sum().item()\n",
    "                val_examples += yb.size(0)\n",
    "\n",
    "        val_loss /= val_examples\n",
    "        val_acc  = val_correct / val_examples\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | \"\n",
    "                f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "                f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    # Load best state\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # ---- Test ----\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            logits = model(Xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            test_correct += (preds == yb).float().sum().item()\n",
    "            test_examples += yb.size(0)\n",
    "\n",
    "    test_acc = test_correct / test_examples if test_examples > 0 else float(\"nan\")\n",
    "    print(f\"Best val acc={best_val_acc:.4f} | Test acc={test_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"window_size\": window_size,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"best_val_acc\": best_val_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b39ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GRU price+4h: W=20, hidden=32, layers=1 ===\n",
      "Train windows: 162 Val windows: 19 Test windows: 19\n",
      "Best val acc=0.4737 | Test acc=0.5789\n",
      "W=20, hidden=32 | best_val_acc=0.4737, test_acc=0.5789\n",
      "\n",
      "=== GRU price+4h: W=20, hidden=64, layers=1 ===\n",
      "Train windows: 162 Val windows: 19 Test windows: 19\n",
      "Best val acc=0.4737 | Test acc=0.5789\n",
      "W=20, hidden=64 | best_val_acc=0.4737, test_acc=0.5789\n",
      "\n",
      "=== GRU price+4h: W=30, hidden=32, layers=1 ===\n",
      "Train windows: 152 Val windows: 9 Test windows: 9\n",
      "Best val acc=0.5556 | Test acc=0.5556\n",
      "W=30, hidden=32 | best_val_acc=0.5556, test_acc=0.5556\n",
      "\n",
      "=== GRU price+4h: W=30, hidden=64, layers=1 ===\n",
      "Train windows: 152 Val windows: 9 Test windows: 9\n",
      "Best val acc=0.5556 | Test acc=0.5556\n",
      "W=30, hidden=64 | best_val_acc=0.5556, test_acc=0.5556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_size  hidden_dim  num_layers  best_val_acc  test_acc\n",
       "0           20          32           1      0.473684  0.578947\n",
       "1           20          64           1      0.473684  0.578947\n",
       "2           30          32           1      0.555556  0.555556\n",
       "3           30          64           1      0.555556  0.555556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_configs = [\n",
    "    {\"window_size\": 20, \"hidden_dim\": 32, \"num_layers\": 1},\n",
    "    {\"window_size\": 20, \"hidden_dim\": 64, \"num_layers\": 1},\n",
    "    {\"window_size\": 30, \"hidden_dim\": 32, \"num_layers\": 1},\n",
    "    {\"window_size\": 30, \"hidden_dim\": 64, \"num_layers\": 1},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for cfg in experiment_configs:\n",
    "    res = train_gru_price_plus_4h(\n",
    "        window_size=cfg[\"window_size\"],\n",
    "        hidden_dim=cfg[\"hidden_dim\"],\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        batch_size=32,\n",
    "        num_epochs=20,\n",
    "        lr=1e-3,\n",
    "        verbose=False,  # flip to True if you want full logs\n",
    "    )\n",
    "    print(\n",
    "        f\"W={res['window_size']}, hidden={res['hidden_dim']} \"\n",
    "        f\"| best_val_acc={res['best_val_acc']:.4f}, test_acc={res['test_acc']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
