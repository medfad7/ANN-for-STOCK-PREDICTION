{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5e5502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1354c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/KDP only/Documents/ANN_Final_Project/spy-ann/data/processed/daily_merged.parquet'),\n",
       " WindowsPath('C:/Users/KDP only/Documents/ANN_Final_Project/spy-ann/data/processed/news_daily_features.parquet'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "PRICE_PATH = DATA_PROCESSED / \"daily_merged.parquet\"\n",
    "NEWS_PATH  = DATA_PROCESSED / \"news_daily_features.parquet\"\n",
    "\n",
    "PRICE_PATH, NEWS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5afb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRICE DATA PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>ma_close_5</th>\n",
       "      <th>ma_close_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>vol_20</th>\n",
       "      <th>future_price</th>\n",
       "      <th>future_ret_1d</th>\n",
       "      <th>label_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>83.059364</td>\n",
       "      <td>83.217386</td>\n",
       "      <td>81.930636</td>\n",
       "      <td>82.216584</td>\n",
       "      <td>216327900</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.347997</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>83.134609</td>\n",
       "      <td>82.404697</td>\n",
       "      <td>82.683113</td>\n",
       "      <td>172730700</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.004995</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.205024</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>82.043540</td>\n",
       "      <td>80.079552</td>\n",
       "      <td>82.005919</td>\n",
       "      <td>356715700</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>81.734995</td>\n",
       "      <td>83.931498</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>80.425666</td>\n",
       "      <td>78.694953</td>\n",
       "      <td>80.184871</td>\n",
       "      <td>493585800</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>81.625131</td>\n",
       "      <td>83.648186</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>80.764291</td>\n",
       "      <td>79.620510</td>\n",
       "      <td>80.320322</td>\n",
       "      <td>224166900</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>81.148059</td>\n",
       "      <td>83.321606</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>80.681526</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      Close       High        Low       Open     Volume    ret_1d  \\\n",
       "0 2010-02-02  83.059364  83.217386  81.930636  82.216584  216327900  0.012104   \n",
       "1 2010-02-03  82.645493  83.134609  82.404697  82.683113  172730700 -0.004983   \n",
       "2 2010-02-04  80.094604  82.043540  80.079552  82.005919  356715700 -0.030865   \n",
       "3 2010-02-05  80.260124  80.425666  78.694953  80.184871  493585800  0.002067   \n",
       "4 2010-02-08  79.680710  80.764291  79.620510  80.320322  224166900 -0.007219   \n",
       "\n",
       "   log_ret_1d  ma_close_5  ma_close_20     vol_5    vol_20  future_price  \\\n",
       "0    0.012031   82.055548    84.347997  0.012653  0.010585     82.645493   \n",
       "1   -0.004995   82.055548    84.205024  0.012873  0.010574     80.094604   \n",
       "2   -0.031352   81.734995    83.931498  0.018783  0.012403     80.260124   \n",
       "3    0.002064   81.625131    83.648186  0.018457  0.012344     79.680710   \n",
       "4   -0.007245   81.148059    83.321606  0.015917  0.012270     80.681526   \n",
       "\n",
       "   future_ret_1d  label_up  \n",
       "0      -0.004983         0  \n",
       "1      -0.030865         0  \n",
       "2       0.002067         1  \n",
       "3      -0.007219         0  \n",
       "4       0.012560         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3753, 15)\n",
      "Date range: 2010-02-02 00:00:00 → 2024-12-30 00:00:00\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.552625\n",
      "0    0.447375\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_price = pd.read_parquet(PRICE_PATH)\n",
    "df_price[\"date\"] = pd.to_datetime(df_price[\"date\"])\n",
    "\n",
    "print(\"=== PRICE DATA PREVIEW ===\")\n",
    "display(df_price.head())\n",
    "print(\"Shape:\", df_price.shape)\n",
    "print(\"Date range:\", df_price[\"date\"].min(), \"→\", df_price[\"date\"].max())\n",
    "print(\"Label distribution:\")\n",
    "print(df_price[\"label_up\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2519fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NEWS DAILY FEATURES PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news_sent_mean</th>\n",
       "      <th>news_sent_std</th>\n",
       "      <th>news_n_headlines</th>\n",
       "      <th>news_frac_pos</th>\n",
       "      <th>news_frac_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0.127267</td>\n",
       "      <td>0.220432</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>-0.542300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>-0.177900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>-0.200950</td>\n",
       "      <td>0.284186</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  news_sent_mean  news_sent_std  news_n_headlines  news_frac_pos  \\\n",
       "0 2010-01-05        0.127267       0.220432                 3       0.333333   \n",
       "1 2010-01-06       -0.542300       0.000000                 1       0.000000   \n",
       "2 2010-01-07        0.000000       0.000000                 1       0.000000   \n",
       "3 2010-01-11       -0.177900       0.000000                 1       0.000000   \n",
       "4 2010-01-13       -0.200950       0.284186                 2       0.000000   \n",
       "\n",
       "   news_frac_neg  \n",
       "0            0.0  \n",
       "1            1.0  \n",
       "2            0.0  \n",
       "3            1.0  \n",
       "4            0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3311, 6)\n",
      "Date range: 2010-01-05 00:00:00 → 2024-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_parquet(NEWS_PATH)\n",
    "df_news[\"date\"] = pd.to_datetime(df_news[\"date\"])\n",
    "\n",
    "print(\"=== NEWS DAILY FEATURES PREVIEW ===\")\n",
    "display(df_news.head())\n",
    "print(\"Shape:\", df_news.shape)\n",
    "print(\"Date range:\", df_news[\"date\"].min(), \"→\", df_news[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MERGED PRICE + NEWS PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>ma_close_5</th>\n",
       "      <th>ma_close_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>vol_20</th>\n",
       "      <th>future_price</th>\n",
       "      <th>future_ret_1d</th>\n",
       "      <th>label_up</th>\n",
       "      <th>news_sent_mean</th>\n",
       "      <th>news_sent_std</th>\n",
       "      <th>news_n_headlines</th>\n",
       "      <th>news_frac_pos</th>\n",
       "      <th>news_frac_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>83.059364</td>\n",
       "      <td>83.217386</td>\n",
       "      <td>81.930636</td>\n",
       "      <td>82.216584</td>\n",
       "      <td>216327900</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.347997</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>82.043540</td>\n",
       "      <td>80.079552</td>\n",
       "      <td>82.005919</td>\n",
       "      <td>356715700</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>81.734995</td>\n",
       "      <td>83.931498</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>80.425666</td>\n",
       "      <td>78.694953</td>\n",
       "      <td>80.184871</td>\n",
       "      <td>493585800</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>81.625131</td>\n",
       "      <td>83.648186</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>80.764291</td>\n",
       "      <td>79.620510</td>\n",
       "      <td>80.320322</td>\n",
       "      <td>224166900</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>81.148059</td>\n",
       "      <td>83.321606</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>80.681526</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.52538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>81.298500</td>\n",
       "      <td>81.343647</td>\n",
       "      <td>80.147199</td>\n",
       "      <td>80.508388</td>\n",
       "      <td>304622100</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>80.710101</td>\n",
       "      <td>82.285435</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>82.577789</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      Close       High        Low       Open     Volume    ret_1d  \\\n",
       "0 2010-02-02  83.059364  83.217386  81.930636  82.216584  216327900  0.012104   \n",
       "1 2010-02-04  80.094604  82.043540  80.079552  82.005919  356715700 -0.030865   \n",
       "2 2010-02-05  80.260124  80.425666  78.694953  80.184871  493585800  0.002067   \n",
       "3 2010-02-08  79.680710  80.764291  79.620510  80.320322  224166900 -0.007219   \n",
       "4 2010-02-12  81.298500  81.343647  80.147199  80.508388  304622100 -0.000833   \n",
       "\n",
       "   log_ret_1d  ma_close_5  ma_close_20     vol_5    vol_20  future_price  \\\n",
       "0    0.012031   82.055548    84.347997  0.012653  0.010585     82.645493   \n",
       "1   -0.031352   81.734995    83.931498  0.018783  0.012403     80.260124   \n",
       "2    0.002064   81.625131    83.648186  0.018457  0.012344     79.680710   \n",
       "3   -0.007245   81.148059    83.321606  0.015917  0.012270     80.681526   \n",
       "4   -0.000833   80.710101    82.285435  0.008516  0.012735     82.577789   \n",
       "\n",
       "   future_ret_1d  label_up  news_sent_mean  news_sent_std  news_n_headlines  \\\n",
       "0      -0.004983         0          0.0000        0.00000                 1   \n",
       "1       0.002067         1          0.0000        0.00000                 1   \n",
       "2      -0.007219         0          0.5160        0.00000                 1   \n",
       "3       0.012560         1          0.3715        0.52538                 2   \n",
       "4       0.015736         1          0.0000        0.00000                 1   \n",
       "\n",
       "   news_frac_pos  news_frac_neg  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            1.0            0.0  \n",
       "3            0.5            0.0  \n",
       "4            0.0            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3303, 20)\n",
      "Date range: 2010-02-02 00:00:00 → 2024-03-04 00:00:00\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.548895\n",
      "0    0.451105\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Columns:\n",
      "['date', 'Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20', 'future_price', 'future_ret_1d', 'label_up', 'news_sent_mean', 'news_sent_std', 'news_n_headlines', 'news_frac_pos', 'news_frac_neg']\n"
     ]
    }
   ],
   "source": [
    "START_DATE = pd.to_datetime(\"2010-01-01\")   # or \"2018-01-01\" if you want tighter\n",
    "END_DATE   = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "df_price_cut = df_price[(df_price[\"date\"] >= START_DATE) & (df_price[\"date\"] <= END_DATE)].copy()\n",
    "df_news_cut  = df_news[(df_news[\"date\"] >= START_DATE) & (df_news[\"date\"] <= END_DATE)].copy()\n",
    "\n",
    "df = (\n",
    "    df_price_cut\n",
    "    .merge(df_news_cut, on=\"date\", how=\"inner\")\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"=== MERGED PRICE + NEWS PREVIEW ===\")\n",
    "display(df.head())\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Date range:\", df[\"date\"].min(), \"→\", df[\"date\"].max())\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label_up\"].value_counts(normalize=True))\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c3e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs per column before drop:\n",
      "date                0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "ret_1d              0\n",
      "log_ret_1d          0\n",
      "ma_close_5          0\n",
      "ma_close_20         0\n",
      "vol_5               0\n",
      "vol_20              0\n",
      "future_price        0\n",
      "future_ret_1d       0\n",
      "label_up            0\n",
      "news_sent_mean      0\n",
      "news_sent_std       0\n",
      "news_n_headlines    0\n",
      "news_frac_pos       0\n",
      "news_frac_neg       0\n",
      "dtype: int64\n",
      "\n",
      "After dropna:\n",
      "Shape: (3303, 20)\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.548895\n",
      "0    0.451105\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs per column before drop:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAfter dropna:\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label_up\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ea486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes:\n",
      "Train: 2018\n",
      "Val: 747\n",
      "Test: 538\n",
      "\n",
      "Train date range: 2010-02-02 00:00:00 → 2018-12-31 00:00:00\n",
      "Val   date range: 2019-01-02 00:00:00 → 2021-12-31 00:00:00\n",
      "Test  date range: 2022-01-03 00:00:00 → 2024-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "TRAIN_END = \"2018-12-31\"\n",
    "VAL_END   = \"2021-12-31\"\n",
    "\n",
    "def make_time_splits(df, train_end, val_end):\n",
    "    dates = pd.to_datetime(df[\"date\"])\n",
    "    train_idx = np.where(dates <= pd.to_datetime(train_end))[0]\n",
    "    val_idx   = np.where((dates > pd.to_datetime(train_end)) & (dates <= pd.to_datetime(val_end)))[0]\n",
    "    test_idx  = np.where(dates > pd.to_datetime(val_end))[0]\n",
    "    return SimpleNamespace(train_idx=train_idx, val_idx=val_idx, test_idx=test_idx)\n",
    "\n",
    "splits = make_time_splits(df, TRAIN_END, VAL_END)\n",
    "\n",
    "print(\"Split sizes:\")\n",
    "print(\"Train:\", len(splits.train_idx))\n",
    "print(\"Val:\",   len(splits.val_idx))\n",
    "print(\"Test:\",  len(splits.test_idx))\n",
    "\n",
    "print(\"\\nTrain date range:\", df.loc[splits.train_idx, \"date\"].min(), \"→\", df.loc[splits.train_idx, \"date\"].max())\n",
    "print(\"Val   date range:\",   df.loc[splits.val_idx,   \"date\"].min(), \"→\", df.loc[splits.val_idx,   \"date\"].max())\n",
    "print(\"Test  date range:\",   df.loc[splits.test_idx,  \"date\"].min(), \"→\", df.loc[splits.test_idx,  \"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d4fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label_up mean: 0.5496  (up=54.96%, down=45.04%)\n",
      "val label_up mean: 0.5810  (up=58.10%, down=41.90%)\n",
      "test label_up mean: 0.5019  (up=50.19%, down=49.81%)\n"
     ]
    }
   ],
   "source": [
    "for name, idx in [(\"train\", splits.train_idx), (\"val\", splits.val_idx), (\"test\", splits.test_idx)]:\n",
    "    p_up = df.loc[idx, \"label_up\"].mean()\n",
    "    print(f\"{name} label_up mean: {p_up:.4f}  (up={p_up:.2%}, down={1-p_up:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d128247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price-only features: ['Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20']\n",
      "Price+news features: ['Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20', 'news_sent_mean', 'news_sent_std', 'news_n_headlines', 'news_frac_pos', 'news_frac_neg']\n"
     ]
    }
   ],
   "source": [
    "# price features (same as before)\n",
    "price_features = [\n",
    "    \"Close\", \"High\", \"Low\", \"Open\", \"Volume\",\n",
    "    \"ret_1d\", \"log_ret_1d\",\n",
    "    \"ma_close_5\", \"ma_close_20\",\n",
    "    \"vol_5\", \"vol_20\",\n",
    "]\n",
    "\n",
    "# news features from your daily aggregation\n",
    "news_features = [\n",
    "    \"news_sent_mean\",\n",
    "    \"news_sent_std\",\n",
    "    \"news_n_headlines\",\n",
    "    \"news_frac_pos\",\n",
    "    \"news_frac_neg\",\n",
    "]\n",
    "\n",
    "for f in price_features + news_features:\n",
    "    if f not in df.columns:\n",
    "        print(\"WARNING: missing feature:\", f)\n",
    "\n",
    "price_plus_news_features = price_features + news_features\n",
    "\n",
    "print(\"Price-only features:\", price_features)\n",
    "print(\"Price+news features:\", price_plus_news_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d02336b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (price-only): (2018, 11) (747, 11) (538, 11)\n",
      "Shapes (price+news): (2018, 16) (747, 16) (538, 16)\n"
     ]
    }
   ],
   "source": [
    "y_all = df[\"label_up\"].values.astype(\"float32\")\n",
    "\n",
    "X_price = df[price_features].values.astype(\"float32\")\n",
    "X_price_news = df[price_plus_news_features].values.astype(\"float32\")\n",
    "\n",
    "train_idx, val_idx, test_idx = splits.train_idx, splits.val_idx, splits.test_idx\n",
    "\n",
    "def split_arrays(X):\n",
    "    return X[train_idx], X[val_idx], X[test_idx]\n",
    "\n",
    "Xtr_price, Xval_price, Xte_price = split_arrays(X_price)\n",
    "Xtr_price_news, Xval_price_news, Xte_price_news = split_arrays(X_price_news)\n",
    "\n",
    "y_train, y_val, y_test = y_all[train_idx], y_all[val_idx], y_all[test_idx]\n",
    "\n",
    "print(\"Shapes (price-only):\", Xtr_price.shape, Xval_price.shape, Xte_price.shape)\n",
    "print(\"Shapes (price+news):\", Xtr_price_news.shape, Xval_price_news.shape, Xte_price_news.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c12070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label_up mean: 0.5496  (up=54.96%, down=45.04%)\n",
      "pos_weight_value: 0.8196574268117109\n"
     ]
    }
   ],
   "source": [
    "p_up_train = float(y_train.mean())\n",
    "p_down_train = 1.0 - p_up_train\n",
    "\n",
    "print(f\"Train label_up mean: {p_up_train:.4f}  (up={p_up_train:.2%}, down={p_down_train:.2%})\")\n",
    "\n",
    "# For BCEWithLogitsLoss, pos_weight ~ N_neg / N_pos\n",
    "pos_weight_value = p_down_train / p_up_train\n",
    "pos_weight_tensor = torch.tensor(pos_weight_value, device=device, dtype=torch.float32)\n",
    "\n",
    "print(\"pos_weight_value:\", pos_weight_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0951052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_price = StandardScaler().fit(Xtr_price)\n",
    "Xtr_price_scaled = scaler_price.transform(Xtr_price)\n",
    "Xval_price_scaled = scaler_price.transform(Xval_price)\n",
    "Xte_price_scaled  = scaler_price.transform(Xte_price)\n",
    "\n",
    "scaler_price_news = StandardScaler().fit(Xtr_price_news)\n",
    "Xtr_price_news_scaled = scaler_price_news.transform(Xtr_price_news)\n",
    "Xval_price_news_scaled = scaler_price_news.transform(Xval_price_news)\n",
    "Xte_price_news_scaled  = scaler_price_news.transform(Xte_price_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b954b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq):\n",
    "        self.X = torch.from_numpy(X_seq).float()\n",
    "        self.y = torch.from_numpy(y_seq).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def build_windows(X, y, window_size):\n",
    "    \"\"\"\n",
    "    X: (T, F), y: (T,)\n",
    "    Returns:\n",
    "      X_seq: (N, W, F)\n",
    "      y_seq: (N,), label at t+W (next day after window)\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    T = len(X)\n",
    "    for t in range(T - window_size):\n",
    "        X_seq.append(X[t:t+window_size])\n",
    "        y_seq.append(y[t+window_size-1])\n",
    "    return np.stack(X_seq), np.array(y_seq, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b677d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWindow(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes=(64, 32)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, F)\n",
    "        b, w, f = x.shape\n",
    "        x = x.view(b, w * f)\n",
    "        logits = self.net(x).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, F)\n",
    "        out, h_n = self.gru(x)\n",
    "        last_hidden = h_n[-1]   # (B, hidden_dim)\n",
    "        logits = self.fc(last_hidden).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe36b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq_model(\n",
    "    model,\n",
    "    Xtr, ytr,\n",
    "    Xval, yval,\n",
    "    Xte, yte,\n",
    "    window_size=30,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    "):\n",
    "    # Build windows\n",
    "    Xtr_seq, ytr_seq = build_windows(Xtr, ytr, window_size)\n",
    "    Xval_seq, yval_seq = build_windows(Xval, yval, window_size)\n",
    "    Xte_seq, yte_seq = build_windows(Xte, yte, window_size)\n",
    "\n",
    "    print(f\"Train windows: {Xtr_seq.shape[0]} Val: {Xval_seq.shape[0]} Test: {Xte_seq.shape[0]}\")\n",
    "\n",
    "    train_ds = SeqDataset(Xtr_seq, ytr_seq)\n",
    "    val_ds   = SeqDataset(Xval_seq, yval_seq)\n",
    "    test_ds  = SeqDataset(Xte_seq, yte_seq)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # train\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            total_correct += (preds == yb).float().sum().item()\n",
    "            total_examples += yb.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        train_acc = total_correct / total_examples\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                val_loss += loss.item() * yb.size(0)\n",
    "                val_correct += (preds == yb).float().sum().item()\n",
    "                val_examples += yb.size(0)\n",
    "\n",
    "        val_loss /= val_examples\n",
    "        val_acc = val_correct / val_examples\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} \"\n",
    "                f\"| val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # test\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_examples = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            test_correct += (preds == yb).float().sum().item()\n",
    "            test_examples += yb.size(0)\n",
    "\n",
    "            all_true.append(yb.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    test_acc = test_correct / test_examples\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    print(f\"Best val_acc={best_val_acc:.4f} | test_acc={test_acc:.4f}\")\n",
    "    print(\"Test mean(true):\", all_true.mean())\n",
    "    print(\"Test mean(pred):\", all_pred.mean())\n",
    "\n",
    "    return best_val_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f6f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ PRICE-ONLY vs PRICE+NEWS (W=30) ================\n",
      "\n",
      "=== MLP price-only ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5676 | test_acc=0.4921\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.5531496\n",
      "\n",
      "=== MLP price+news ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5732 | test_acc=0.5276\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.68700784\n",
      "\n",
      "=== GRU price-only ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5788 | test_acc=0.4783\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.070866145\n",
      "\n",
      "=== GRU price+news ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5858 | test_acc=0.5079\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.8917323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>window_size</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.492126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.527559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.578801</td>\n",
       "      <td>0.478346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.507874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model    features  window_size   val_acc  test_acc\n",
       "0   MLP  price_only           30  0.567643  0.492126\n",
       "1   MLP  price+news           30  0.573222  0.527559\n",
       "2   GRU  price_only           30  0.578801  0.478346\n",
       "3   GRU  price+news           30  0.585774  0.507874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = 30\n",
    "results = []\n",
    "\n",
    "print(\"================ PRICE-ONLY vs PRICE+NEWS (W=30) ================\")\n",
    "\n",
    "# 1) MLP price-only\n",
    "mlp_price = MLPWindow(input_dim=W * Xtr_price_scaled.shape[1], hidden_sizes=(64, 32))\n",
    "print(\"\\n=== MLP price-only ===\")\n",
    "val_acc_po_mlp, test_acc_po_mlp = train_seq_model(\n",
    "    mlp_price,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"MLP\",\n",
    "    \"features\": \"price_only\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_po_mlp,\n",
    "    \"test_acc\": test_acc_po_mlp,\n",
    "})\n",
    "\n",
    "# 2) MLP price+news\n",
    "mlp_price_news = MLPWindow(input_dim=W * Xtr_price_news_scaled.shape[1], hidden_sizes=(64, 32))\n",
    "print(\"\\n=== MLP price+news ===\")\n",
    "val_acc_pn_mlp, test_acc_pn_mlp = train_seq_model(\n",
    "    mlp_price_news,\n",
    "    Xtr_price_news_scaled, y_train,\n",
    "    Xval_price_news_scaled, y_val,\n",
    "    Xte_price_news_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"MLP\",\n",
    "    \"features\": \"price+news\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_pn_mlp,\n",
    "    \"test_acc\": test_acc_pn_mlp,\n",
    "})\n",
    "\n",
    "# 3) GRU price-only\n",
    "gru_price = GRUNet(input_dim=Xtr_price_scaled.shape[1], hidden_dim=32, num_layers=1)\n",
    "print(\"\\n=== GRU price-only ===\")\n",
    "val_acc_po_gru, test_acc_po_gru = train_seq_model(\n",
    "    gru_price,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"GRU\",\n",
    "    \"features\": \"price_only\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_po_gru,\n",
    "    \"test_acc\": test_acc_po_gru,\n",
    "})\n",
    "\n",
    "# 4) GRU price+news\n",
    "gru_price_news = GRUNet(input_dim=Xtr_price_news_scaled.shape[1], hidden_dim=32, num_layers=1)\n",
    "print(\"\\n=== GRU price+news ===\")\n",
    "val_acc_pn_gru, test_acc_pn_gru = train_seq_model(\n",
    "    gru_price_news,\n",
    "    Xtr_price_news_scaled, y_train,\n",
    "    Xval_price_news_scaled, y_val,\n",
    "    Xte_price_news_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"GRU\",\n",
    "    \"features\": \"price+news\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_pn_gru,\n",
    "    \"test_acc\": test_acc_pn_gru,\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57b0412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>window_size</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.567643</td>\n",
       "      <td>0.492126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.527559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.578801</td>\n",
       "      <td>0.478346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.507874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model    features  window_size   val_acc  test_acc\n",
       "0   MLP  price_only           30  0.567643  0.492126\n",
       "1   MLP  price+news           30  0.573222  0.527559\n",
       "2   GRU  price_only           30  0.578801  0.478346\n",
       "3   GRU  price+news           30  0.585774  0.507874"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "x_labels = [f\"{m}\\n{f}\" for m, f in zip(results_df[\"model\"], results_df[\"features\"])]\n",
    "plt.bar(range(len(results_df)), results_df[\"test_acc\"].values)\n",
    "plt.xticks(range(len(results_df)), x_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.title(\"Price-only vs Price+News (W=30)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ab373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq):\n",
    "        self.X = torch.from_numpy(X_seq).float()\n",
    "        self.y = torch.from_numpy(y_seq).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def build_windows(X, y, window_size):\n",
    "    X_seq, y_seq = [], []\n",
    "    T = len(X)\n",
    "    for t in range(T - window_size):\n",
    "        X_seq.append(X[t:t+window_size])\n",
    "        y_seq.append(y[t+window_size-1])\n",
    "    return np.stack(X_seq), np.array(y_seq, dtype=\"float32\")\n",
    "\n",
    "\n",
    "def train_seq_model_reg(\n",
    "    model,\n",
    "    Xtr, ytr,\n",
    "    Xval, yval,\n",
    "    Xte, yte,\n",
    "    window_size=30,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    # Build windows\n",
    "    Xtr_seq, ytr_seq = build_windows(Xtr, ytr, window_size)\n",
    "    Xval_seq, yval_seq = build_windows(Xval, yval, window_size)\n",
    "    Xte_seq, yte_seq = build_windows(Xte, yte, window_size)\n",
    "\n",
    "    print(f\"Train windows: {Xtr_seq.shape[0]} Val: {Xval_seq.shape[0]} Test: {Xte_seq.shape[0]}\")\n",
    "\n",
    "    train_ds = SeqDataset(Xtr_seq, ytr_seq)\n",
    "    val_ds   = SeqDataset(Xval_seq, yval_seq)\n",
    "    test_ds  = SeqDataset(Xte_seq, yte_seq)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if pos_weight is not None:\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,   # <-- L2 regularization\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            total_correct += (preds == yb).float().sum().item()\n",
    "            total_examples += yb.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        train_acc = total_correct / total_examples\n",
    "\n",
    "        # ----- Val -----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                val_loss += loss.item() * yb.size(0)\n",
    "                val_correct += (preds == yb).float().sum().item()\n",
    "                val_examples += yb.size(0)\n",
    "\n",
    "        val_loss /= val_examples\n",
    "        val_acc = val_correct / val_examples\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} \"\n",
    "                f\"| val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # ----- Test -----\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_examples = 0\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            test_correct += (preds == yb).float().sum().item()\n",
    "            test_examples += yb.size(0)\n",
    "\n",
    "            all_true.append(yb.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    test_acc = test_correct / test_examples\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    print(f\"[REG] Best val_acc={best_val_acc:.4f} | test_acc={test_acc:.4f}\")\n",
    "    print(\"Test mean(true):\", all_true.mean())\n",
    "    print(\"Test mean(pred):\", all_pred.mean())\n",
    "\n",
    "    return best_val_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67cb2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ADVANCED: GRU price-only with regularization ==========\n",
      "\n",
      "GRU price-only (baseline, no reg):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5844 | test_acc=0.5197\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.41141734\n",
      "\n",
      "GRU price-only (weight_decay=1e-4):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5858 | test_acc=0.5335\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.9448819\n",
      "\n",
      "GRU price-only (weight_decay=1e-4 + pos_weight):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5886 | test_acc=0.5138\n",
      "Test mean(true): 0.5098425\n",
      "Test mean(pred): 0.6496063\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU price-only baseline</td>\n",
       "      <td>0.584379</td>\n",
       "      <td>0.519685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU price-only + L2(1e-4)</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.533465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU price-only + L2(1e-4) + pos_weight</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.513780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   config   val_acc  test_acc\n",
       "0                 GRU price-only baseline  0.584379  0.519685\n",
       "1               GRU price-only + L2(1e-4)  0.585774  0.533465\n",
       "2  GRU price-only + L2(1e-4) + pos_weight  0.588563  0.513780"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim_price = Xtr_price_scaled.shape[1]\n",
    "W = 30\n",
    "\n",
    "results_reg = []\n",
    "\n",
    "print(\"========== ADVANCED: GRU price-only with regularization ==========\")\n",
    "\n",
    "# 1) Baseline (no reg, no class weight) – for comparison\n",
    "gru_base = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (baseline, no reg):\")\n",
    "val_acc_base, test_acc_base = train_seq_model_reg(\n",
    "    gru_base,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only baseline\",\n",
    "    \"val_acc\": val_acc_base,\n",
    "    \"test_acc\": test_acc_base,\n",
    "})\n",
    "\n",
    "# 2) L2 weight decay only\n",
    "gru_l2 = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (weight_decay=1e-4):\")\n",
    "val_acc_l2, test_acc_l2 = train_seq_model_reg(\n",
    "    gru_l2,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only + L2(1e-4)\",\n",
    "    \"val_acc\": val_acc_l2,\n",
    "    \"test_acc\": test_acc_l2,\n",
    "})\n",
    "\n",
    "# 3) L2 + class-weighted loss\n",
    "gru_l2_cw = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (weight_decay=1e-4 + pos_weight):\")\n",
    "val_acc_l2_cw, test_acc_l2_cw = train_seq_model_reg(\n",
    "    gru_l2_cw,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    pos_weight=pos_weight_tensor,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only + L2(1e-4) + pos_weight\",\n",
    "    \"val_acc\": val_acc_l2_cw,\n",
    "    \"test_acc\": test_acc_l2_cw,\n",
    "})\n",
    "\n",
    "pd.DataFrame(results_reg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
