{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb5e5502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f1354c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/KDP only/Documents/ANN_Final_Project/spy-ann/data/processed/daily_merged.parquet'),\n",
       " WindowsPath('C:/Users/KDP only/Documents/ANN_Final_Project/spy-ann/data/processed/news_daily_features.parquet'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "PRICE_PATH = DATA_PROCESSED / \"daily_merged.parquet\"\n",
    "NEWS_PATH  = DATA_PROCESSED / \"news_daily_features.parquet\"\n",
    "\n",
    "PRICE_PATH, NEWS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b5afb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRICE DATA PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>ma_close_5</th>\n",
       "      <th>ma_close_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>vol_20</th>\n",
       "      <th>future_price</th>\n",
       "      <th>future_ret_1d</th>\n",
       "      <th>label_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>83.059364</td>\n",
       "      <td>83.217386</td>\n",
       "      <td>81.930636</td>\n",
       "      <td>82.216584</td>\n",
       "      <td>216327900</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.347997</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>83.134609</td>\n",
       "      <td>82.404697</td>\n",
       "      <td>82.683113</td>\n",
       "      <td>172730700</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.004995</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.205024</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>82.043540</td>\n",
       "      <td>80.079552</td>\n",
       "      <td>82.005919</td>\n",
       "      <td>356715700</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>81.734995</td>\n",
       "      <td>83.931498</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>80.425666</td>\n",
       "      <td>78.694953</td>\n",
       "      <td>80.184871</td>\n",
       "      <td>493585800</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>81.625131</td>\n",
       "      <td>83.648186</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>80.764291</td>\n",
       "      <td>79.620510</td>\n",
       "      <td>80.320322</td>\n",
       "      <td>224166900</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>81.148059</td>\n",
       "      <td>83.321606</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>80.681526</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      Close       High        Low       Open     Volume    ret_1d  \\\n",
       "0 2010-02-02  83.059364  83.217386  81.930636  82.216584  216327900  0.012104   \n",
       "1 2010-02-03  82.645493  83.134609  82.404697  82.683113  172730700 -0.004983   \n",
       "2 2010-02-04  80.094604  82.043540  80.079552  82.005919  356715700 -0.030865   \n",
       "3 2010-02-05  80.260124  80.425666  78.694953  80.184871  493585800  0.002067   \n",
       "4 2010-02-08  79.680710  80.764291  79.620510  80.320322  224166900 -0.007219   \n",
       "\n",
       "   log_ret_1d  ma_close_5  ma_close_20     vol_5    vol_20  future_price  \\\n",
       "0    0.012031   82.055548    84.347997  0.012653  0.010585     82.645493   \n",
       "1   -0.004995   82.055548    84.205024  0.012873  0.010574     80.094604   \n",
       "2   -0.031352   81.734995    83.931498  0.018783  0.012403     80.260124   \n",
       "3    0.002064   81.625131    83.648186  0.018457  0.012344     79.680710   \n",
       "4   -0.007245   81.148059    83.321606  0.015917  0.012270     80.681526   \n",
       "\n",
       "   future_ret_1d  label_up  \n",
       "0      -0.004983         0  \n",
       "1      -0.030865         0  \n",
       "2       0.002067         1  \n",
       "3      -0.007219         0  \n",
       "4       0.012560         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3753, 15)\n",
      "Date range: 2010-02-02 00:00:00 → 2024-12-30 00:00:00\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.552625\n",
      "0    0.447375\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_price = pd.read_parquet(PRICE_PATH)\n",
    "df_price[\"date\"] = pd.to_datetime(df_price[\"date\"])\n",
    "\n",
    "print(\"=== PRICE DATA PREVIEW ===\")\n",
    "display(df_price.head())\n",
    "print(\"Shape:\", df_price.shape)\n",
    "print(\"Date range:\", df_price[\"date\"].min(), \"→\", df_price[\"date\"].max())\n",
    "print(\"Label distribution:\")\n",
    "print(df_price[\"label_up\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2519fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NEWS DAILY FEATURES PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news_sent_mean</th>\n",
       "      <th>news_sent_std</th>\n",
       "      <th>news_n_headlines</th>\n",
       "      <th>news_frac_pos</th>\n",
       "      <th>news_frac_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0.127267</td>\n",
       "      <td>0.220432</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>-0.542300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>-0.177900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>-0.200950</td>\n",
       "      <td>0.284186</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  news_sent_mean  news_sent_std  news_n_headlines  news_frac_pos  \\\n",
       "0 2010-01-05        0.127267       0.220432                 3       0.333333   \n",
       "1 2010-01-06       -0.542300       0.000000                 1       0.000000   \n",
       "2 2010-01-07        0.000000       0.000000                 1       0.000000   \n",
       "3 2010-01-11       -0.177900       0.000000                 1       0.000000   \n",
       "4 2010-01-13       -0.200950       0.284186                 2       0.000000   \n",
       "\n",
       "   news_frac_neg  \n",
       "0            0.0  \n",
       "1            1.0  \n",
       "2            0.0  \n",
       "3            1.0  \n",
       "4            0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3311, 6)\n",
      "Date range: 2010-01-05 00:00:00 → 2024-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_parquet(NEWS_PATH)\n",
    "df_news[\"date\"] = pd.to_datetime(df_news[\"date\"])\n",
    "\n",
    "print(\"=== NEWS DAILY FEATURES PREVIEW ===\")\n",
    "display(df_news.head())\n",
    "print(\"Shape:\", df_news.shape)\n",
    "print(\"Date range:\", df_news[\"date\"].min(), \"→\", df_news[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MERGED PRICE + NEWS PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>ma_close_5</th>\n",
       "      <th>ma_close_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>vol_20</th>\n",
       "      <th>future_price</th>\n",
       "      <th>future_ret_1d</th>\n",
       "      <th>label_up</th>\n",
       "      <th>news_sent_mean</th>\n",
       "      <th>news_sent_std</th>\n",
       "      <th>news_n_headlines</th>\n",
       "      <th>news_frac_pos</th>\n",
       "      <th>news_frac_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>83.059364</td>\n",
       "      <td>83.217386</td>\n",
       "      <td>81.930636</td>\n",
       "      <td>82.216584</td>\n",
       "      <td>216327900</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>82.055548</td>\n",
       "      <td>84.347997</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>82.645493</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>80.094604</td>\n",
       "      <td>82.043540</td>\n",
       "      <td>80.079552</td>\n",
       "      <td>82.005919</td>\n",
       "      <td>356715700</td>\n",
       "      <td>-0.030865</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>81.734995</td>\n",
       "      <td>83.931498</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>80.260124</td>\n",
       "      <td>80.425666</td>\n",
       "      <td>78.694953</td>\n",
       "      <td>80.184871</td>\n",
       "      <td>493585800</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>81.625131</td>\n",
       "      <td>83.648186</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>79.680710</td>\n",
       "      <td>80.764291</td>\n",
       "      <td>79.620510</td>\n",
       "      <td>80.320322</td>\n",
       "      <td>224166900</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>-0.007245</td>\n",
       "      <td>81.148059</td>\n",
       "      <td>83.321606</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>80.681526</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.52538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>81.298500</td>\n",
       "      <td>81.343647</td>\n",
       "      <td>80.147199</td>\n",
       "      <td>80.508388</td>\n",
       "      <td>304622100</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>80.710101</td>\n",
       "      <td>82.285435</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>82.577789</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      Close       High        Low       Open     Volume    ret_1d  \\\n",
       "0 2010-02-02  83.059364  83.217386  81.930636  82.216584  216327900  0.012104   \n",
       "1 2010-02-04  80.094604  82.043540  80.079552  82.005919  356715700 -0.030865   \n",
       "2 2010-02-05  80.260124  80.425666  78.694953  80.184871  493585800  0.002067   \n",
       "3 2010-02-08  79.680710  80.764291  79.620510  80.320322  224166900 -0.007219   \n",
       "4 2010-02-12  81.298500  81.343647  80.147199  80.508388  304622100 -0.000833   \n",
       "\n",
       "   log_ret_1d  ma_close_5  ma_close_20     vol_5    vol_20  future_price  \\\n",
       "0    0.012031   82.055548    84.347997  0.012653  0.010585     82.645493   \n",
       "1   -0.031352   81.734995    83.931498  0.018783  0.012403     80.260124   \n",
       "2    0.002064   81.625131    83.648186  0.018457  0.012344     79.680710   \n",
       "3   -0.007245   81.148059    83.321606  0.015917  0.012270     80.681526   \n",
       "4   -0.000833   80.710101    82.285435  0.008516  0.012735     82.577789   \n",
       "\n",
       "   future_ret_1d  label_up  news_sent_mean  news_sent_std  news_n_headlines  \\\n",
       "0      -0.004983         0          0.0000        0.00000                 1   \n",
       "1       0.002067         1          0.0000        0.00000                 1   \n",
       "2      -0.007219         0          0.5160        0.00000                 1   \n",
       "3       0.012560         1          0.3715        0.52538                 2   \n",
       "4       0.015736         1          0.0000        0.00000                 1   \n",
       "\n",
       "   news_frac_pos  news_frac_neg  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            1.0            0.0  \n",
       "3            0.5            0.0  \n",
       "4            0.0            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3303, 20)\n",
      "Date range: 2010-02-02 00:00:00 → 2024-03-04 00:00:00\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.548895\n",
      "0    0.451105\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Columns:\n",
      "['date', 'Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20', 'future_price', 'future_ret_1d', 'label_up', 'news_sent_mean', 'news_sent_std', 'news_n_headlines', 'news_frac_pos', 'news_frac_neg']\n"
     ]
    }
   ],
   "source": [
    "START_DATE = pd.to_datetime(\"2010-01-01\")   # or \"2018-01-01\" if you want tighter\n",
    "END_DATE   = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "df_price_cut = df_price[(df_price[\"date\"] >= START_DATE) & (df_price[\"date\"] <= END_DATE)].copy()\n",
    "df_news_cut  = df_news[(df_news[\"date\"] >= START_DATE) & (df_news[\"date\"] <= END_DATE)].copy()\n",
    "\n",
    "df = (\n",
    "    df_price_cut\n",
    "    .merge(df_news_cut, on=\"date\", how=\"inner\")\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"=== MERGED PRICE + NEWS PREVIEW ===\")\n",
    "display(df.head())\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Date range:\", df[\"date\"].min(), \"→\", df[\"date\"].max())\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label_up\"].value_counts(normalize=True))\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20c3e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs per column before drop:\n",
      "date                0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "ret_1d              0\n",
      "log_ret_1d          0\n",
      "ma_close_5          0\n",
      "ma_close_20         0\n",
      "vol_5               0\n",
      "vol_20              0\n",
      "future_price        0\n",
      "future_ret_1d       0\n",
      "label_up            0\n",
      "news_sent_mean      0\n",
      "news_sent_std       0\n",
      "news_n_headlines    0\n",
      "news_frac_pos       0\n",
      "news_frac_neg       0\n",
      "dtype: int64\n",
      "\n",
      "After dropna:\n",
      "Shape: (3303, 20)\n",
      "Label distribution:\n",
      "label_up\n",
      "1    0.548895\n",
      "0    0.451105\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs per column before drop:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAfter dropna:\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"label_up\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13ea486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes:\n",
      "Train: 2018\n",
      "Val: 747\n",
      "Test: 538\n",
      "\n",
      "Train date range: 2010-02-02 00:00:00 → 2018-12-31 00:00:00\n",
      "Val   date range: 2019-01-02 00:00:00 → 2021-12-31 00:00:00\n",
      "Test  date range: 2022-01-03 00:00:00 → 2024-03-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "TRAIN_END = \"2018-12-31\"\n",
    "VAL_END   = \"2021-12-31\"\n",
    "\n",
    "def make_time_splits(df, train_end, val_end):\n",
    "    dates = pd.to_datetime(df[\"date\"])\n",
    "    train_idx = np.where(dates <= pd.to_datetime(train_end))[0]\n",
    "    val_idx   = np.where((dates > pd.to_datetime(train_end)) & (dates <= pd.to_datetime(val_end)))[0]\n",
    "    test_idx  = np.where(dates > pd.to_datetime(val_end))[0]\n",
    "    return SimpleNamespace(train_idx=train_idx, val_idx=val_idx, test_idx=test_idx)\n",
    "\n",
    "splits = make_time_splits(df, TRAIN_END, VAL_END)\n",
    "\n",
    "print(\"Split sizes:\")\n",
    "print(\"Train:\", len(splits.train_idx))\n",
    "print(\"Val:\",   len(splits.val_idx))\n",
    "print(\"Test:\",  len(splits.test_idx))\n",
    "\n",
    "print(\"\\nTrain date range:\", df.loc[splits.train_idx, \"date\"].min(), \"→\", df.loc[splits.train_idx, \"date\"].max())\n",
    "print(\"Val   date range:\",   df.loc[splits.val_idx,   \"date\"].min(), \"→\", df.loc[splits.val_idx,   \"date\"].max())\n",
    "print(\"Test  date range:\",   df.loc[splits.test_idx,  \"date\"].min(), \"→\", df.loc[splits.test_idx,  \"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06d4fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label_up mean: 0.5496  (up=54.96%, down=45.04%)\n",
      "val label_up mean: 0.5810  (up=58.10%, down=41.90%)\n",
      "test label_up mean: 0.5019  (up=50.19%, down=49.81%)\n"
     ]
    }
   ],
   "source": [
    "for name, idx in [(\"train\", splits.train_idx), (\"val\", splits.val_idx), (\"test\", splits.test_idx)]:\n",
    "    p_up = df.loc[idx, \"label_up\"].mean()\n",
    "    print(f\"{name} label_up mean: {p_up:.4f}  (up={p_up:.2%}, down={1-p_up:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d128247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price-only features: ['Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20']\n",
      "Price+news features: ['Close', 'High', 'Low', 'Open', 'Volume', 'ret_1d', 'log_ret_1d', 'ma_close_5', 'ma_close_20', 'vol_5', 'vol_20', 'news_sent_mean', 'news_sent_std', 'news_n_headlines', 'news_frac_pos', 'news_frac_neg']\n"
     ]
    }
   ],
   "source": [
    "# price features (same as before)\n",
    "price_features = [\n",
    "    \"Close\", \"High\", \"Low\", \"Open\", \"Volume\",\n",
    "    \"ret_1d\", \"log_ret_1d\",\n",
    "    \"ma_close_5\", \"ma_close_20\",\n",
    "    \"vol_5\", \"vol_20\",\n",
    "]\n",
    "\n",
    "# news features from your daily aggregation\n",
    "news_features = [\n",
    "    \"news_sent_mean\",\n",
    "    \"news_sent_std\",\n",
    "    \"news_n_headlines\",\n",
    "    \"news_frac_pos\",\n",
    "    \"news_frac_neg\",\n",
    "]\n",
    "\n",
    "for f in price_features + news_features:\n",
    "    if f not in df.columns:\n",
    "        print(\"WARNING: missing feature:\", f)\n",
    "\n",
    "price_plus_news_features = price_features + news_features\n",
    "\n",
    "print(\"Price-only features:\", price_features)\n",
    "print(\"Price+news features:\", price_plus_news_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d02336b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (price-only): (2018, 11) (747, 11) (538, 11)\n",
      "Shapes (price+news): (2018, 16) (747, 16) (538, 16)\n"
     ]
    }
   ],
   "source": [
    "y_all = df[\"label_up\"].values.astype(\"float32\")\n",
    "\n",
    "X_price = df[price_features].values.astype(\"float32\")\n",
    "X_price_news = df[price_plus_news_features].values.astype(\"float32\")\n",
    "\n",
    "train_idx, val_idx, test_idx = splits.train_idx, splits.val_idx, splits.test_idx\n",
    "\n",
    "def split_arrays(X):\n",
    "    return X[train_idx], X[val_idx], X[test_idx]\n",
    "\n",
    "Xtr_price, Xval_price, Xte_price = split_arrays(X_price)\n",
    "Xtr_price_news, Xval_price_news, Xte_price_news = split_arrays(X_price_news)\n",
    "\n",
    "y_train, y_val, y_test = y_all[train_idx], y_all[val_idx], y_all[test_idx]\n",
    "\n",
    "print(\"Shapes (price-only):\", Xtr_price.shape, Xval_price.shape, Xte_price.shape)\n",
    "print(\"Shapes (price+news):\", Xtr_price_news.shape, Xval_price_news.shape, Xte_price_news.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c12070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label_up mean: 0.5496  (up=54.96%, down=45.04%)\n",
      "pos_weight_value: 0.8196574268117109\n"
     ]
    }
   ],
   "source": [
    "p_up_train = float(y_train.mean())\n",
    "p_down_train = 1.0 - p_up_train\n",
    "\n",
    "print(f\"Train label_up mean: {p_up_train:.4f}  (up={p_up_train:.2%}, down={p_down_train:.2%})\")\n",
    "\n",
    "# For BCEWithLogitsLoss, pos_weight ~ N_neg / N_pos\n",
    "pos_weight_value = p_down_train / p_up_train\n",
    "pos_weight_tensor = torch.tensor(pos_weight_value, device=device, dtype=torch.float32)\n",
    "\n",
    "print(\"pos_weight_value:\", pos_weight_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0951052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_price = StandardScaler().fit(Xtr_price)\n",
    "Xtr_price_scaled = scaler_price.transform(Xtr_price)\n",
    "Xval_price_scaled = scaler_price.transform(Xval_price)\n",
    "Xte_price_scaled  = scaler_price.transform(Xte_price)\n",
    "\n",
    "scaler_price_news = StandardScaler().fit(Xtr_price_news)\n",
    "Xtr_price_news_scaled = scaler_price_news.transform(Xtr_price_news)\n",
    "Xval_price_news_scaled = scaler_price_news.transform(Xval_price_news)\n",
    "Xte_price_news_scaled  = scaler_price_news.transform(Xte_price_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41b954b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq):\n",
    "        self.X = torch.from_numpy(X_seq).float()\n",
    "        self.y = torch.from_numpy(y_seq).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def build_windows(X, y, window_size):\n",
    "    \"\"\"\n",
    "    X: (T, F), y: (T,)\n",
    "    Returns:\n",
    "      X_seq: (N, W, F)\n",
    "      y_seq: (N,), label at t+W (next day after window)\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    T = len(X)\n",
    "    for t in range(T - window_size):\n",
    "        X_seq.append(X[t:t+window_size])\n",
    "        y_seq.append(y[t+window_size])\n",
    "    return np.stack(X_seq), np.array(y_seq, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9b677d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWindow(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes=(64, 32)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, F)\n",
    "        b, w, f = x.shape\n",
    "        x = x.view(b, w * f)\n",
    "        logits = self.net(x).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, F)\n",
    "        out, h_n = self.gru(x)\n",
    "        last_hidden = h_n[-1]   # (B, hidden_dim)\n",
    "        logits = self.fc(last_hidden).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfe36b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq_model(\n",
    "    model,\n",
    "    Xtr, ytr,\n",
    "    Xval, yval,\n",
    "    Xte, yte,\n",
    "    window_size=30,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    "):\n",
    "    # Build windows\n",
    "    Xtr_seq, ytr_seq = build_windows(Xtr, ytr, window_size)\n",
    "    Xval_seq, yval_seq = build_windows(Xval, yval, window_size)\n",
    "    Xte_seq, yte_seq = build_windows(Xte, yte, window_size)\n",
    "\n",
    "    print(f\"Train windows: {Xtr_seq.shape[0]} Val: {Xval_seq.shape[0]} Test: {Xte_seq.shape[0]}\")\n",
    "\n",
    "    train_ds = SeqDataset(Xtr_seq, ytr_seq)\n",
    "    val_ds   = SeqDataset(Xval_seq, yval_seq)\n",
    "    test_ds  = SeqDataset(Xte_seq, yte_seq)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # train\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            total_correct += (preds == yb).float().sum().item()\n",
    "            total_examples += yb.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        train_acc = total_correct / total_examples\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                val_loss += loss.item() * yb.size(0)\n",
    "                val_correct += (preds == yb).float().sum().item()\n",
    "                val_examples += yb.size(0)\n",
    "\n",
    "        val_loss /= val_examples\n",
    "        val_acc = val_correct / val_examples\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} \"\n",
    "                f\"| val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # test\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_examples = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            test_correct += (preds == yb).float().sum().item()\n",
    "            test_examples += yb.size(0)\n",
    "\n",
    "            all_true.append(yb.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    test_acc = test_correct / test_examples\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    print(f\"Best val_acc={best_val_acc:.4f} | test_acc={test_acc:.4f}\")\n",
    "    print(\"Test mean(true):\", all_true.mean())\n",
    "    print(\"Test mean(pred):\", all_pred.mean())\n",
    "\n",
    "    return best_val_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46f6f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ PRICE-ONLY vs PRICE+NEWS (W=30) ================\n",
      "\n",
      "=== MLP price-only ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5662 | test_acc=0.4882\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.031496063\n",
      "\n",
      "=== MLP price+news ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5732 | test_acc=0.5177\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.6082677\n",
      "\n",
      "=== GRU price-only ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5872 | test_acc=0.5118\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.996063\n",
      "\n",
      "=== GRU price+news ===\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "Best val_acc=0.5816 | test_acc=0.5059\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.96259844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>window_size</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.488189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.517717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.511811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.505906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model    features  window_size   val_acc  test_acc\n",
       "0   MLP  price_only           30  0.566248  0.488189\n",
       "1   MLP  price+news           30  0.573222  0.517717\n",
       "2   GRU  price_only           30  0.587169  0.511811\n",
       "3   GRU  price+news           30  0.581590  0.505906"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = 30\n",
    "results = []\n",
    "\n",
    "print(\"================ PRICE-ONLY vs PRICE+NEWS (W=30) ================\")\n",
    "\n",
    "# 1) MLP price-only\n",
    "mlp_price = MLPWindow(input_dim=W * Xtr_price_scaled.shape[1], hidden_sizes=(64, 32))\n",
    "print(\"\\n=== MLP price-only ===\")\n",
    "val_acc_po_mlp, test_acc_po_mlp = train_seq_model(\n",
    "    mlp_price,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"MLP\",\n",
    "    \"features\": \"price_only\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_po_mlp,\n",
    "    \"test_acc\": test_acc_po_mlp,\n",
    "})\n",
    "\n",
    "# 2) MLP price+news\n",
    "mlp_price_news = MLPWindow(input_dim=W * Xtr_price_news_scaled.shape[1], hidden_sizes=(64, 32))\n",
    "print(\"\\n=== MLP price+news ===\")\n",
    "val_acc_pn_mlp, test_acc_pn_mlp = train_seq_model(\n",
    "    mlp_price_news,\n",
    "    Xtr_price_news_scaled, y_train,\n",
    "    Xval_price_news_scaled, y_val,\n",
    "    Xte_price_news_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"MLP\",\n",
    "    \"features\": \"price+news\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_pn_mlp,\n",
    "    \"test_acc\": test_acc_pn_mlp,\n",
    "})\n",
    "\n",
    "# 3) GRU price-only\n",
    "gru_price = GRUNet(input_dim=Xtr_price_scaled.shape[1], hidden_dim=32, num_layers=1)\n",
    "print(\"\\n=== GRU price-only ===\")\n",
    "val_acc_po_gru, test_acc_po_gru = train_seq_model(\n",
    "    gru_price,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"GRU\",\n",
    "    \"features\": \"price_only\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_po_gru,\n",
    "    \"test_acc\": test_acc_po_gru,\n",
    "})\n",
    "\n",
    "# 4) GRU price+news\n",
    "gru_price_news = GRUNet(input_dim=Xtr_price_news_scaled.shape[1], hidden_dim=32, num_layers=1)\n",
    "print(\"\\n=== GRU price+news ===\")\n",
    "val_acc_pn_gru, test_acc_pn_gru = train_seq_model(\n",
    "    gru_price_news,\n",
    "    Xtr_price_news_scaled, y_train,\n",
    "    Xval_price_news_scaled, y_val,\n",
    "    Xte_price_news_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    verbose=False,\n",
    ")\n",
    "results.append({\n",
    "    \"model\": \"GRU\",\n",
    "    \"features\": \"price+news\",\n",
    "    \"window_size\": W,\n",
    "    \"val_acc\": val_acc_pn_gru,\n",
    "    \"test_acc\": test_acc_pn_gru,\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f57b0412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>window_size</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.566248</td>\n",
       "      <td>0.488189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.517717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price_only</td>\n",
       "      <td>30</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.511811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>price+news</td>\n",
       "      <td>30</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.505906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model    features  window_size   val_acc  test_acc\n",
       "0   MLP  price_only           30  0.566248  0.488189\n",
       "1   MLP  price+news           30  0.573222  0.517717\n",
       "2   GRU  price_only           30  0.587169  0.511811\n",
       "3   GRU  price+news           30  0.581590  0.505906"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "x_labels = [f\"{m}\\n{f}\" for m, f in zip(results_df[\"model\"], results_df[\"features\"])]\n",
    "plt.bar(range(len(results_df)), results_df[\"test_acc\"].values)\n",
    "plt.xticks(range(len(results_df)), x_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.title(\"Price-only vs Price+News (W=30)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2ab373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq):\n",
    "        self.X = torch.from_numpy(X_seq).float()\n",
    "        self.y = torch.from_numpy(y_seq).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def build_windows(X, y, window_size):\n",
    "    X_seq, y_seq = [], []\n",
    "    T = len(X)\n",
    "    for t in range(T - window_size):\n",
    "        X_seq.append(X[t:t+window_size])\n",
    "        y_seq.append(y[t+window_size])\n",
    "    return np.stack(X_seq), np.array(y_seq, dtype=\"float32\")\n",
    "\n",
    "\n",
    "def train_seq_model_reg(\n",
    "    model,\n",
    "    Xtr, ytr,\n",
    "    Xval, yval,\n",
    "    Xte, yte,\n",
    "    window_size=30,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    # Build windows\n",
    "    Xtr_seq, ytr_seq = build_windows(Xtr, ytr, window_size)\n",
    "    Xval_seq, yval_seq = build_windows(Xval, yval, window_size)\n",
    "    Xte_seq, yte_seq = build_windows(Xte, yte, window_size)\n",
    "\n",
    "    print(f\"Train windows: {Xtr_seq.shape[0]} Val: {Xval_seq.shape[0]} Test: {Xte_seq.shape[0]}\")\n",
    "\n",
    "    train_ds = SeqDataset(Xtr_seq, ytr_seq)\n",
    "    val_ds   = SeqDataset(Xval_seq, yval_seq)\n",
    "    test_ds  = SeqDataset(Xte_seq, yte_seq)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if pos_weight is not None:\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,   # <-- L2 regularization\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ----- Train -----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            total_correct += (preds == yb).float().sum().item()\n",
    "            total_examples += yb.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        train_acc = total_correct / total_examples\n",
    "\n",
    "        # ----- Val -----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_examples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, yb)\n",
    "\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                val_loss += loss.item() * yb.size(0)\n",
    "                val_correct += (preds == yb).float().sum().item()\n",
    "                val_examples += yb.size(0)\n",
    "\n",
    "        val_loss /= val_examples\n",
    "        val_acc = val_correct / val_examples\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} \"\n",
    "                f\"| val_loss={val_loss:.4f} acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # ----- Test -----\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_examples = 0\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            test_correct += (preds == yb).float().sum().item()\n",
    "            test_examples += yb.size(0)\n",
    "\n",
    "            all_true.append(yb.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    test_acc = test_correct / test_examples\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    print(f\"[REG] Best val_acc={best_val_acc:.4f} | test_acc={test_acc:.4f}\")\n",
    "    print(\"Test mean(true):\", all_true.mean())\n",
    "    print(\"Test mean(pred):\", all_pred.mean())\n",
    "\n",
    "    return best_val_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67cb2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ADVANCED: GRU price-only with regularization ==========\n",
      "\n",
      "GRU price-only (baseline, no reg):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5886 | test_acc=0.5138\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.9901575\n",
      "\n",
      "GRU price-only (weight_decay=1e-4):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5774 | test_acc=0.5276\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.8228347\n",
      "\n",
      "GRU price-only (weight_decay=1e-4 + pos_weight):\n",
      "Train windows: 1988 Val: 717 Test: 508\n",
      "[REG] Best val_acc=0.5816 | test_acc=0.4921\n",
      "Test mean(true): 0.507874\n",
      "Test mean(pred): 0.007874016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU price-only baseline</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>0.513780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU price-only + L2(1e-4)</td>\n",
       "      <td>0.577406</td>\n",
       "      <td>0.527559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU price-only + L2(1e-4) + pos_weight</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.492126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   config   val_acc  test_acc\n",
       "0                 GRU price-only baseline  0.588563  0.513780\n",
       "1               GRU price-only + L2(1e-4)  0.577406  0.527559\n",
       "2  GRU price-only + L2(1e-4) + pos_weight  0.581590  0.492126"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim_price = Xtr_price_scaled.shape[1]\n",
    "W = 30\n",
    "\n",
    "results_reg = []\n",
    "\n",
    "print(\"========== ADVANCED: GRU price-only with regularization ==========\")\n",
    "\n",
    "# 1) Baseline (no reg, no class weight) – for comparison\n",
    "gru_base = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (baseline, no reg):\")\n",
    "val_acc_base, test_acc_base = train_seq_model_reg(\n",
    "    gru_base,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only baseline\",\n",
    "    \"val_acc\": val_acc_base,\n",
    "    \"test_acc\": test_acc_base,\n",
    "})\n",
    "\n",
    "# 2) L2 weight decay only\n",
    "gru_l2 = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (weight_decay=1e-4):\")\n",
    "val_acc_l2, test_acc_l2 = train_seq_model_reg(\n",
    "    gru_l2,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    pos_weight=None,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only + L2(1e-4)\",\n",
    "    \"val_acc\": val_acc_l2,\n",
    "    \"test_acc\": test_acc_l2,\n",
    "})\n",
    "\n",
    "# 3) L2 + class-weighted loss\n",
    "gru_l2_cw = GRUNet(input_dim=input_dim_price, hidden_dim=32, num_layers=1)\n",
    "print(\"\\nGRU price-only (weight_decay=1e-4 + pos_weight):\")\n",
    "val_acc_l2_cw, test_acc_l2_cw = train_seq_model_reg(\n",
    "    gru_l2_cw,\n",
    "    Xtr_price_scaled, y_train,\n",
    "    Xval_price_scaled, y_val,\n",
    "    Xte_price_scaled, y_test,\n",
    "    window_size=W,\n",
    "    num_epochs=20,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    pos_weight=pos_weight_tensor,\n",
    "    verbose=False,\n",
    ")\n",
    "results_reg.append({\n",
    "    \"config\": \"GRU price-only + L2(1e-4) + pos_weight\",\n",
    "    \"val_acc\": val_acc_l2_cw,\n",
    "    \"test_acc\": test_acc_l2_cw,\n",
    "})\n",
    "\n",
    "pd.DataFrame(results_reg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
